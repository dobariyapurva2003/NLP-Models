# ğŸ§  NLP Sentiment Analysis: Comparative Study using BERT, LSTM, GRU, and RNN

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red?logo=pytorch)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

This project performs sentiment analysis using four deep learning models â€” BERT, LSTM, GRU, and simple RNN â€” and compares them on classification performance, computational efficiency, and implementation complexity. Built using PyTorch and Hugging Face Transformers.

---

## ğŸ“ Project Structure

```
NLP-Sentiment-Model-Comparison/
â”œâ”€â”€ main.ipynb 		# Main notebook with training and evaluation
â”œâ”€â”€ requirements.txt                            # Python dependencies
â”œâ”€â”€ README.md                                   # Project overview

[Models](https://drive.google.com/drive/folders/1KyBVUQT_m9mhYF8p5eI3m7wFqKZSWRE3?usp=sharing)
[Dataset-BERT](https://www.kaggle.com/datasets/virajjayant/bertbaseuncased)
[Dataset-Glove](https://www.kaggle.com/datasets/danielwillgeorge/glove6b100dtxt)
[Dataset-IMDB Movie review](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)
```

---

## ğŸ§  Models Compared

|   Model  |  			   Summary 			    |
|----------|--------------------------------------------------------|
| **BERT** | Pre-trained transformer from Hugging Face (fine-tuned) |
| **LSTM** | Long Short-Term Memory network for sequential modeling |
| **GRU**  | Gated Recurrent Unit for efficient RNN-based modeling |
| **RNN**  | Baseline simple Recurrent Neural Network |

---

ğŸ“Š Evaluation Metrics

âœ… Accuracy
âœ… Precision, Recall, F1-Score
âœ… Confusion Matrix
âœ… ROC-AUC
âœ… Training Time & Memory Usage

---

ğŸ›  Built With

- Python 3.10+
- PyTorch
- Hugging Face Transformers
- scikit-learn
- Jupyter Notebook
- matplotlib, seaborn, numpy, pandas

---
